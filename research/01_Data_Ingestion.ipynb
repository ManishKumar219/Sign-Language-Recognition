{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\projects\\\\MLOps\\\\Sign-Language-Recognition'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    raw_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sign_Language.constants import *\n",
    "from Sign_Language.utils.common import create_directories, read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            raw_data_path=config.raw_data_path \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mp123\\AppData\\Local\\Temp\\ipykernel_18556\\3202271884.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Sign_Language import logger\n",
    "from Sign_Language.utils.common import get_size\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def load_file(self):\n",
    "        if not os.path.exists(self.config.raw_data_path):\n",
    "            df = pd.read_csv(\"research/data/Data.csv\")\n",
    "            logger.info(f\"Read the Raw dataset as DataFrame: {self.config.raw_data_path}\")\n",
    "\n",
    "            df.to_csv(self.config.raw_data_path, index=False)\n",
    "\n",
    "            # traindf, testdf = train_test_split(df, test_size=0.2, random_state=12)\n",
    "\n",
    "            # traindf.to_csv(self.config.train_data_path, index=False)\n",
    "            # testdf.to_csv(self.config.test_data_path, index=False)\n",
    "\n",
    "            logger.info(f\"loaded the raw dataset: {self.config.raw_data_path}\")\n",
    "\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: {get_size(Path(self.config.raw_data_path))}\")\n",
    "\n",
    "    def create_train_test_data(self):\n",
    "        if not os.path.exists(self.config.train_data_path):\n",
    "            df = pd.read_csv(self.config.raw_data_path)\n",
    "            traindf, testdf = train_test_split(df, test_size=0.2, random_state=12)\n",
    "\n",
    "            traindf.to_csv(self.config.train_data_path, index=False)\n",
    "            testdf.to_csv(self.config.test_data_path, index=False)\n",
    "\n",
    "            logger.info(\"Created the training and test data\")\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: \\n \\\n",
    "                        {get_size(Path(self.config.train_data_path))} \\n\\\n",
    "                        {get_size(Path(self.config.train_data_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-09 02:11:39,930: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-09 02:11:39,951: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-09 02:11:39,956: INFO: common: created directory at: artifacts]\n",
      "[2024-02-09 02:11:39,960: INFO: common: created directory at: artifacts/data-ingestion]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-09 02:11:41,546: INFO: 1709612983: Read the Raw dataset as DataFrame: artifacts/data-ingestion/data.csv]\n",
      "[2024-02-09 02:11:50,369: INFO: 1709612983: loaded the raw dataset: artifacts/data-ingestion/data.csv]\n",
      "[2024-02-09 02:11:57,007: INFO: 1709612983: Created the training and test data]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.load_file()\n",
    "    data_ingestion.create_train_test_data()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aslenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
